# -*- coding: utf-8 -*-
"""vit-pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16hxEFirnC_oaYT9hMsjmJxU6-KYlKwf0
"""

import torch
import torchvision

print(torch.__version__)
print(torchvision.__version__)


device = "cuda" if torch.cuda.is_available() else "cpu"

!nvidia-smi

# # For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+
# try:
#     import torch
#     import torchvision
#     assert int(torch.__version__.split(".")[1]) >= 12, "torch version should be 1.12+"
#     assert int(torchvision.__version__.split(".")[1]) >= 13, "torchvision version should be 0.13+"
#     print(f"torch version: {torch.__version__}")
#     print(f"torchvision version: {torchvision.__version__}")
# except:
#     print(f"[INFO] torch/torchvision versions not as required, installing nightly versions.")
#     !pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121
#     import torch
#     import torchvision
#     print(f"torch version: {torch.__version__}")
#     print(f"torchvision version: {torchvision.__version__}")

# Continue with regular imports
import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

# Try to get torchinfo, install it if it doesn't work
try:
    from torchinfo import summary
except:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

# Try to import the going_modular directory, download it from GitHub if it doesn't work
try:
    from going_modular.going_modular import data_setup, engine
except:
    # Get the going_modular scripts
    print("[INFO] Couldn't find going_modular scripts... downloading them from GitHub.")
    !git clone https://github.com/mrdbourke/pytorch-deep-learning
    !mv pytorch-deep-learning/going_modular .
    !rm -rf pytorch-deep-learning
    from going_modular.going_modular import data_setup, engine

import os
import zipfile

from pathlib import Path

import requests

data_path = Path("data/")
image_path = data_path /"pizza_steak_sushi"

if image_path.is_dir():
  print(f"{image_path} exists")
else:
  print(f"{image_path} not found")
  image_path.mkdir(parents=True, exist_ok=True)

  with open(data_path / "pizza_steak_sushi.zip", 'wb') as f:
    request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
    print("downloading data")
    f.write(request.content)

  with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
    print("Unzipping")
    zip_ref.extractall(image_path)

    os.remove(data_path / 'pizza_steak_sushi.zip')

# Setup directory paths to train and test images
train_dir = image_path / "train"
test_dir = image_path / "test"

from torchvision import transforms

IMG_SIZE = 224

manual_transforms = torchvision.transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor()
])
manual_transforms

BATCH_SIZE = 32
NUM_WORKERS = 2

train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=manual_transforms,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS
)

len(train_dataloader), len(test_dataloader), class_names

image_batch, label_batch = next(iter(train_dataloader))

image, label = image_batch[0], label_batch[0]

image.shape, label.shape

import matplotlib.pyplot as plt

plt.imshow(image.permute(1, 2, 0))
plt.axis(False);

import torch.nn as nn


class ViTBase(nn.Module):

  def __init__(self, img_size,
               num_layers=12,
               num_heads=12,
               patch_size =16,
               hidden_size=768,
               num_channels=3):
    super().__init__()

    self.num_patches = (img_size // patch_size) **2 # Calculate N

    self.patch_embed = nn.Linear(patch_size * patch_size * 3, hidden_size) # Patch embed dim (hidden_size, hidden_size)

    self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_size)) # A class token of batch_size, 1, 768

    self.positional_embeddings = nn.Parameter(torch.randn(1, self.num_patches+1, hidden_size)) # projection of positional embeddings batch_size, N+1, hidden_size

    self.layer_norm = nn.LayerNorm(hidden_size)

    encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size,
                                               nhead=num_heads)
    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

    self.classifier = nn.Linear(hidden_size, 3)

  def forward(self, x):
    batch_size = x.size(0)
    x = x.view(batch_size, self.num_patches, -1)

    x = self.patch_embed(x)
    cls_token = self.cls_token.expand(batch_size, -1, -1) # Shape ( batch_size, 1, D)
    x = torch.cat((cls_token, x), dim=1)
    x = x + self.positional_embeddings
    x = self.layer_norm(x)
    x = self.transformer_encoder(x)
    cls_output = x[:, 0]
    out = self.classifier(cls_output)

    return out

model = ViTBase(img_size=224,
                patch_size=16).to(device)
model

torch.manual_seed(42)
torch.cuda.manual_seed(42)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)

results = engine.train(
    model=model,
    train_dataloader=train_dataloader,
    test_dataloader=test_dataloader,
    optimizer=optimizer,
    loss_fn=loss_fn,
    epochs=10,
    device=device
)

plt.imshow(image_batch[10].permute(1, 2, 0))
plt.title(f"Predictions: {class_names[torch.argmax(torch.softmax(model(image_batch[10].unsqueeze(0).to(device)), dim=1), dim=1)]}")
plt.show();

# Create random input sizes
random_input_image = (32, 3, 224, 224)
random_input_image_error = (1, 3, 250, 250) # will error because image size is incompatible with patch_size

# Get a summary of the input and outputs of PatchEmbedding (uncomment for full output)
summary(model,
        input_size=random_input_image, # try swapping this for "random_input_image_error"
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"])

